<html>
<head>
<title>Using the React Speech Recognition Hook for voice assistance - LogRocket Blog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>使用 React 语音识别钩子进行语音辅助</h1>
<blockquote>原文：<a href="https://blog.logrocket.com/using-the-react-speech-recognition-hook-for-voice-assistance/#0001-01-01">https://blog.logrocket.com/using-the-react-speech-recognition-hook-for-voice-assistance/#0001-01-01</a></blockquote><div><article class="article-post">
<p>在本教程中，我们将向您展示如何使用 React 语音识别在 React 应用程序中实现语音辅助。</p>
<p>我们将讨论以下内容:</p>

<h2 id="whatisreactspeechrecognition">什么是 React 语音识别？</h2>
<p><a href="https://github.com/JamesBrill/react-speech-recognition#readme"> React 语音识别</a>是一个<a href="https://blog.logrocket.com/react-hooks-cheat-sheet-unlock-solutions-to-common-problems-af4caf699e70/"> React 挂钩</a>，它与 Web 语音 API 一起工作，将来自设备麦克风的语音翻译成文本。然后，React 应用程序可以读取这些文本并用来执行任务。</p>
<p>React 语音识别提供了一个命令选项，用于根据特定的语音短语执行特定的任务。例如，当用户询问天气信息时，您可以执行天气 API 调用。这只是一个基本的例子，但当涉及到语音辅助和控制时，<a href="https://voicebot.ai/2021/01/01/over-100-voice-ai-predictions-for-2021-from-50-industry-leaders/">可能性是无限的</a>。</p>
<h3>浏览器支持</h3>
<p>截至 2021 年 2 月，React 语音识别支持以下浏览器:</p>
<ul>
<li>谷歌浏览器(推荐)</li>
<li>微软 Edge</li>
<li>安卓版谷歌浏览器</li>
<li>Android Webview</li>
<li>三星互联网</li>
</ul>
<p>遗憾的是，iOS 不支持这些 API。</p>
<h2 id="reactspeechrecognitionsetupandinstallation">React 语音识别设置和安装</h2>
<p>要将 React 语音识别添加到 React 项目中，只需打开终端并键入:</p>
<pre>npm i --save react-speech-recognition
</pre>
<p>当你按下回车键时，这将把钩子添加到你的项目中。</p>
<h3>构建演示用户界面</h3>
<p>为了了解语音识别挂钩是如何工作的，我们将构建一个简单的 UI。</p>
<p>首先，我们将添加一个带有麦克风图标的圆形按钮，一个带有文本的按钮来指示我们是否在听用户讲话，以及一个停止按钮来停止听。</p>
<p>在这些元素下面，我们将展示用户的语音到文本的翻译，并创建一个重置按钮来清除文本并停止收听。</p>
<p>这是我们对上述组件的 JSX:</p>
<pre>// App.js
function App() {
  return (
    &lt;div className="microphone-wrapper"&gt;
      &lt;div className="mircophone-container"&gt;
        &lt;div className="microphone-icon-container"&gt;
          &lt;img src={microPhoneIcon} className="microphone-icon" /&gt;
        &lt;/div&gt;
        &lt;div className="microphone-status"&gt;
          Click to start Listening
        &lt;/div&gt;
        &lt;button className="microphone-stop btn" &gt;
          Stop
        &lt;/button&gt;
      &lt;/div&gt;

        &lt;div className="microphone-result-container"&gt;
          &lt;div className="microphone-result-text"&gt;Speech text here&lt;/div&gt;
          &lt;button className="microphone-reset btn" &gt;
            Reset
          &lt;/button&gt;
        &lt;/div&gt;

    &lt;/div&gt;
  );
}
</pre>
<p>设置完成后，我们现在可以添加一些样式:</p>
<pre>// App.css
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}
body {
  background-color: rgba(0, 0, 0, 0.8);
  font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
  color: white;
}
.mircophone-container {
  display: flex;
  justify-content: center;
  align-items: center;
  width: 100vw;
  height: 50vh;
}
.microphone-icon-container {
  width: 100px;
  height: 100px;
  border-radius: 50%;
  background-image: linear-gradient(128deg, #ffffff, #647c88);
  padding: 20px;
  margin-right: 20px;
  position: relative;
  cursor: pointer;
}
.microphone-icon-container.listening::before {
  content: "";
  width: 100px;
  height: 100px;
  background-color: #ffffff81;
  position: absolute;
  top: 50%;
  left: 50%;
  transform:translate(-50%, -50%) scale(1.4);
  border-radius: 50%;
  animation: listening infinite 1.5s;
}
@keyframes listening{
  0%{
    opacity: 1;
    transform: translate(-50%, -50%) scale(1);
  }
  100%{
    opacity: 0;
    transform: translate(-50%, -50%) scale(1.4);
  }
}
.microphone-icon {
  width: 100%;
  height: 100%;
}
.microphone-status {
  font-size: 22px;
  margin-right: 20px;
  min-width: 215px;
}
.btn {
  border: none;
  padding: 10px 30px;
  margin-right: 10px;
  outline: none;
  cursor: pointer;
  font-size: 20px;
  border-radius: 25px;
  box-shadow: 0px 0px 10px 5px #ffffff1a;
}
.microphone-result-container {
  text-align: center;
  height: 50vh;

  display: flex;
  flex-direction: column;
  justify-content: space-between;
  align-items: center;
  padding-bottom: 30px;

}
.microphone-result-text {
  margin-bottom: 30px;
  width: 70vw;
  overflow-y: auto;
}
.microphone-reset {
  border: 1px solid #fff;
  background: none;
  color: white;
  width: fit-content;
}
</pre>
<p>您可能已经注意到了，我们还包括了一个动画，当开始收听时会播放，从而提醒用户他们现在可以说话了。</p>
<h2 id="addingreactspeechrecognitionhooks">添加 React 语音识别挂钩</h2>
<p>要使用 React 语音识别，我们必须首先将其导入到组件中。我们将使用<code>useSpeechRecognition</code>钩子和<code>SpeechRecognition</code>对象。</p>
<p>要导入 React 语音识别:</p>
<pre>import SpeechRecognition, { useSpeechRecognition } from "react-speech-recognition";
</pre>
<p>要开始听用户的声音，我们需要调用<code>startListening</code>函数:</p>
<pre>SpeechRecognition.startListening()
</pre>
<p>要停止监听，我们可以调用<code>stopListening</code>:</p>
<pre>SpeechRecognition.stopListening()
</pre>
<p>为了获得用户发言的文本，我们将使用<code>transcript</code>:</p>
<pre>const { transcript } = useSpeechRecognition()
</pre>
<p>无论用户说什么，它都会记录下这个值。</p>
<p>要重置或清除抄本的值，您可以调用<code>resetTranscript</code>:</p>
<pre>const { resetTranscript } = useSpeechRecognition()
</pre>
<p>使用<code>resetTranscript</code>功能会将抄本设置为空。</p>
<p>最后，为了检查浏览器是否支持 Web 语音 API，我们可以使用这个函数:</p>
<pre>if (!SpeechRecognition.browserSupportsSpeechRecognition()) {
  // Browser not supported &amp; return some useful info.
}
</pre>
<h3>完整代码</h3>
<p>至此，我们已经回顾了所有的内容，现在我们可以开始设置代码了。请注意，在下面的块中，我们添加了监听事件和相应的状态:</p>
<pre>import { useRef, useState } from "react";
import SpeechRecognition, { useSpeechRecognition } from "react-speech-recognition";
import "./App.css";
import microPhoneIcon from "./microphone.svg";

function App() {
  const { transcript, resetTranscript } = useSpeechRecognition();
  const [isListening, setIsListening] = useState(false);
  const microphoneRef = useRef(null);
  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {
    return (
      &lt;div className="mircophone-container"&gt;
        Browser is not Support Speech Recognition.
      &lt;/div&gt;
    );
  }
  const handleListing = () =&gt; {
    setIsListening(true);
    microphoneRef.current.classList.add("listening");
    SpeechRecognition.startListening({
      continuous: true,
    });
  };
  const stopHandle = () =&gt; {
    setIsListening(false);
    microphoneRef.current.classList.remove("listening");
    SpeechRecognition.stopListening();
  };
  const handleReset = () =&gt; {
    stopHandle();
    resetTranscript();
  };
  return (
    &lt;div className="microphone-wrapper"&gt;
      &lt;div className="mircophone-container"&gt;
        &lt;div
          className="microphone-icon-container"
          ref={microphoneRef}
          onClick={handleListing}
        &gt;
          &lt;img src={microPhoneIcon} className="microphone-icon" /&gt;
        &lt;/div&gt;
        &lt;div className="microphone-status"&gt;
          {isListening ? "Listening........." : "Click to start Listening"}
        &lt;/div&gt;
        {isListening &amp;&amp; (
          &lt;button className="microphone-stop btn" onClick={stopHandle}&gt;
            Stop
          &lt;/button&gt;
        )}
      &lt;/div&gt;
      {transcript &amp;&amp; (
        &lt;div className="microphone-result-container"&gt;
          &lt;div className="microphone-result-text"&gt;{transcript}&lt;/div&gt;
          &lt;button className="microphone-reset btn" onClick={handleReset}&gt;
            Reset
          &lt;/button&gt;
        &lt;/div&gt;
      )}
    &lt;/div&gt;
  );
}
export default App;
</pre>
<h2 id="usingreactspeechrecognitiontoperformtasks">使用 React 语音识别执行任务</h2>
<p>现在，我们已经设置了应用程序，以便当用户单击麦克风按钮时，应用程序将听到他们的声音，并输出下面的文字记录。第一次运行时，您需要允许麦克风权限。</p>
<p>现在有趣的部分来了:添加命令来执行基于用户语音/短语的任务。</p>
<h3>添加命令</h3>
<p>要添加命令，我们必须将一个数组作为命令选项传递给<code>useSpeechRecognition</code>。然而，在我们这样做之前，我们必须像这样准备我们的命令数组:</p>
<pre>const commands = [
    {
      command: "open *",
      callback: (website) =&gt; {
        window.open("http://" + website.split(" ").join(""));
      },
    },
    {
      command: "change background colour to *",
      callback: (color) =&gt; {
        document.body.style.background = color;
      },
    },
    {
      command: "reset",
      callback: () =&gt; {
        handleReset();
      },
    },
    ,
    {
      command: "reset background colour",
      callback: () =&gt; {
        document.body.style.background = `rgba(0, 0, 0, 0.8)`;
      },
    },
  ];
</pre>
<p>记住<code>commands</code>是带有命令和回调属性的 JSON 对象的数组。出于我们的目的，命令是您将在其中编写命令的属性；回调会相应地触发。</p>
<p>在上面的例子中，您可能已经注意到我们在第一个和第二个命令中传递了一个星号。这个符号允许我们捕获多个单词，并在回调函数中将它们作为变量传递回去。</p>
<p>您可以像这样将<code>commands</code>变量传递给<code>useSpeechRecognition</code>:</p>
<pre>const { transcript, resetTranscript } = useSpeechRecognition({ commands });
</pre>
<p>现在，您应该能够运行您的应用程序和命令了。</p>
<p>为了便于将来参考，我们使用 React 语音识别挂钩创建的应用程序的完整代码如下所示:</p>
<pre>import { useRef, useState } from "react";
import SpeechRecognition, { useSpeechRecognition } from "react-speech-recognition";
import "./App.css";
import microPhoneIcon from "./microphone.svg";
function App() {
  const commands = [
    {
      command: "open *",
      callback: (website) =&gt; {
        window.open("http://" + website.split(" ").join(""));
      },
    },
    {
      command: "change background colour to *",
      callback: (color) =&gt; {
        document.body.style.background = color;
      },
    },
    {
      command: "reset",
      callback: () =&gt; {
        handleReset();
      },
    },
    ,
    {
      command: "reset background colour",
      callback: () =&gt; {
        document.body.style.background = `rgba(0, 0, 0, 0.8)`;
      },
    },
  ];
  const { transcript, resetTranscript } = useSpeechRecognition({ commands });
  const [isListening, setIsListening] = useState(false);
  const microphoneRef = useRef(null);
  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {
    return (
      &lt;div className="mircophone-container"&gt;
        Browser is not Support Speech Recognition.
      &lt;/div&gt;
    );
  }
  const handleListing = () =&gt; {
    setIsListening(true);
    microphoneRef.current.classList.add("listening");
    SpeechRecognition.startListening({
      continuous: true,
    });
  };
  const stopHandle = () =&gt; {
    setIsListening(false);
    microphoneRef.current.classList.remove("listening");
    SpeechRecognition.stopListening();
  };
  const handleReset = () =&gt; {
    stopHandle();
    resetTranscript();
  };
  return (
    &lt;div className="microphone-wrapper"&gt;
      &lt;div className="mircophone-container"&gt;
        &lt;div
          className="microphone-icon-container"
          ref={microphoneRef}
          onClick={handleListing}
        &gt;
          &lt;img src={microPhoneIcon} className="microphone-icon" /&gt;
        &lt;/div&gt;
        &lt;div className="microphone-status"&gt;
          {isListening ? "Listening........." : "Click to start Listening"}
        &lt;/div&gt;
        {isListening &amp;&amp; (
          &lt;button className="microphone-stop btn" onClick={stopHandle}&gt;
            Stop
          &lt;/button&gt;
        )}
      &lt;/div&gt;
      {transcript &amp;&amp; (
        &lt;div className="microphone-result-container"&gt;
          &lt;div className="microphone-result-text"&gt;{transcript}&lt;/div&gt;
          &lt;button className="microphone-reset btn" onClick={handleReset}&gt;
            Reset
          &lt;/button&gt;
        &lt;/div&gt;
      )}
    &lt;/div&gt;
  );
}
export default App;
</pre>
<h2 id="conclusion">结论</h2>
<p>到目前为止，您应该对如何在项目中使用 React 语音识别挂钩有了更好的理解。对于未来的阅读，我建议学习更多关于语音编程的知识，以及人工智能在你的编码工作中帮助 T2 的其他方法。</p>
<p>感谢您阅读文章。请在下面留下任何反馈或评论。</p><div class="code-block code-block-17">
<div class="blog-plug inline-plug react-plug" vwo-el-id="26283398190">
<h2 vwo-el-id="41600691720">使用 LogRocket 消除传统反应错误报告的噪音</h2>
<a href="https://lp.logrocket.com/blg/react-signup-issue-free" target="_blank" vwo-el-id="19356441070">LogRocket
</a><p>是一款 React analytics 解决方案，可保护您免受数百个误报错误警报的影响，只针对少数真正重要的项目。LogRocket 告诉您 React 应用程序中实际影响用户的最具影响力的 bug 和 UX 问题。</p><a class="signup" href="https://lp.logrocket.com/blg/react-signup-general" target="_blank" rel="noopener noreferrer" vwo-el-id="19356441380">
<img class="first-react-image alignnone size-full wp-image-46 jetpack-lazy-image jetpack-lazy-image--handled" src="../Images/f300c244a1a1cf916df8b4cb02bec6c6.png" vwo-el-id="18272717540" data-lazy-loaded="1" data-original-src="https://files.readme.io/27c94e7-Image_2017-06-05_at_9.46.04_PM.png"/>
</a>
<a class="signup" href="https://lp.logrocket.com/blg/react-signup-general" target="_blank" rel="noopener noreferrer" vwo-el-id="19356441690">
<img class="second-react-image alignnone size-full wp-image-46 jetpack-lazy-image jetpack-lazy-image--handled" src="../Images/d6f5a5dd739296c1dd7aab3d5e77eeb9.png" alt="LogRocket Dashboard Free Trial Banner" vwo-el-id="30720362350" data-lazy-loaded="1" data-original-src="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg.png"/>
</a>
<a href="https://lp.logrocket.com/blg/react-signup-issue-free" target="_blank" rel="noopener noreferrer" vwo-el-id="35866400580">LogRocket
</a><p>自动聚合客户端错误、反应错误边界、还原状态、缓慢的组件加载时间、JS 异常、前端性能指标和用户交互。然后，LogRocket 使用机器学习来通知您影响大多数用户的最具影响力的问题，并提供您修复它所需的上下文。</p><p vwo-el-id="28675661060">关注重要的 React bug—<a class="signup" href="https://lp.logrocket.com/blg/react-signup-issue-free" target="_blank" rel="noopener noreferrer" vwo-el-id="40093418840">今天就试试 LogRocket】。</a></p>
</div></div>

<p class="clearfix"/>
<p class="clearfix"/>
</article>

</div>    
</body>
</html>