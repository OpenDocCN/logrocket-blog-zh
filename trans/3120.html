<html>
<head>
<title>Adding speech-to-text and text-to-speech support in a Flutter app - LogRocket Blog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>在 Flutter app - LogRocket 博客中添加语音到文本和文本到语音的支持</h1>
<blockquote>原文：<a href="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/#0001-01-01">https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/#0001-01-01</a></blockquote><div><article class="article-post">
<p>语音到文本功能将您的语音转换为文本，文本到语音功能大声朗读文本。通过添加这一功能，用户可以通过语音(除了用户手势之外)与您的应用程序进行交互，从而增强用户体验。这可以帮助你建立一个类似谷歌助手的应用程序。</p>
<p>它的工作方式是，你说点什么或者问 app 点什么，app 处理你的请求，然后说出结果。</p>
<p>在本教程中，我们将使用<a href="https://pub.dev/packages/speech_recognition" target="_blank" rel="noopener">语音识别</a>和<a href="https://pub.dev/packages/text_to_speech" target="_blank" rel="noopener">文本到语音转换</a>插件构建一个例子。</p>
<p>我们将一步一步地介绍这个示例，为您构建语音助手应用程序打下基础。我们还将介绍插件默认不处理的情况，比如在 Android 设备上持续监听。</p>
<p>这是它完成后的样子:</p>
<p><img data-attachment-id="122830" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/speech-to-text-completed-app-example/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif" data-orig-size="730,765" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="speech-to-text-completed-app-example" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example-286x300.gif" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif" decoding="async" class="aligncenter wp-image-122830 size-full jetpack-lazy-image" src="../Images/e8be137ce06bd1f230920ca1c1e584a0.png" alt="Speech To Text Completed App Example" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif"/></p><noscript><img data-lazy-fallback="1" data-attachment-id="122830" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/speech-to-text-completed-app-example/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif" data-orig-size="730,765" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="speech-to-text-completed-app-example" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example-286x300.gif" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif" decoding="async" loading="lazy" class="aligncenter wp-image-122830 size-full" src="../Images/e8be137ce06bd1f230920ca1c1e584a0.png" alt="Speech To Text Completed App Example" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-to-text-completed-app-example.gif"/></noscript>
<p>以下是我们将在本教程中介绍的内容:</p>

<h2 id="adding-speech-to-text">在 Flutter 应用程序中添加语音到文本</h2>
<p>在示例应用程序中，当用户点击麦克风按钮时，应用程序开始监听。当用户开始说话时，语音被转换成文本并显示在屏幕上。用户可以通过单击停止按钮来停止监听服务。</p>
<p>您可以通过利用<a href="https://pub.dev/packages/speech_recognition" target="_blank" rel="noopener">语音识别</a>插件来实现这样的需求。在内部，它在 iOS 上使用<a href="https://developer.apple.com/reference/speech" target="_blank" rel="noopener">语音 API </a>，在 Android 上使用<a href="https://developer.android.com/reference/android/speech/SpeechRecognizer.html" target="_blank" rel="noopener">语音识别器</a>。它允许您为支持 iOS10+和 Android 4.1+的设备添加任何语言环境的语音识别。</p>
<p>这个插件提供了几个有用的方法，你可以用来开始、停止和取消监听。</p>
<p>以下是在 Flutter 中添加语音到文本支持的分步说明。</p>
<h3 id="adding-dependencies">步骤 1:添加依赖关系</h3>
<p>第一步从在<code>pubspec.yaml</code>文件中添加依赖关系开始。</p>
<p>文件<code>pubspec.yaml</code>中的内容应该是这样的:</p>
<pre class="language-dart hljs">dependencies:
  flutter:
    sdk: flutter
  cupertino_icons: ^1.0.2
  speech_recognition: ^0.3.0+1 #NEW
</pre>
<h3 id="adding-permissions">步骤 2:添加权限</h3>
<p>对于录制音频的插件，您需要获得 Android 和 iOS 平台的许可。为此，您可以更新特定于平台的文件。</p>
<h4><strong>安卓系统</strong></h4>
<p>在<code>your_project/android/app/src/main/AndroidManifest.xml</code>处找到<code>AndroidManifest.xml</code>文件，并按如下方式更新文件:</p>
<pre class="language-dart hljs">&lt;manifest xmlns:android="http://schemas.android.com/apk/res/android"
    package="com.example.speech_to_text_demo"&gt;

    &lt;!-- 1. Permission --&gt;
    &lt;uses-permission android:name="android.permission.RECORD_AUDIO" /&gt;

    &lt;!-- 2. To overcome bind to recognition service failed issue --&gt;
    &lt;queries&gt;
        &lt;package android:name="com.google.android.googlequicksearchbox"/&gt;
    &lt;/queries&gt;


   &lt;application
        android:label="speech_to_text_demo"
        android:name="${applicationName}"
        android:icon="@mipmap/ic_launcher"&gt;
        &lt;activity
            android:name=".MainActivity"
            android:exported="true"
            android:launchMode="singleTop"
            android:theme="@style/LaunchTheme"
            android:configChanges="orientation|keyboardHidden|keyboard|screenSize|smallestScreenSize|locale|layoutDirection|fontScale|screenLayout|density|uiMode"
            android:hardwareAccelerated="true"
            android:windowSoftInputMode="adjustResize"&gt;
    &lt;/application&gt;
&lt;/manifest&gt;
</pre>
<p>下面是上面代码中的内容:</p>
<ol>
<li>添加<code>android.permission.RECORD_AUDIO</code>以录制音频</li>
<li>这有助于您修复某些 Android 设备上的“绑定到识别服务失败问题”。</li>
</ol>
<h4><strong>对于 iOS </strong></h4>
<p>在<code>your_project/ios/Runner/info.plist</code>找到<code>info.plist</code>文件，并添加以下权限:</p>
<pre class="language-dart hljs">&lt;key&gt;NSMicrophoneUsageDescription&lt;/key&gt;
&lt;string&gt;This application needs to access your microphone&lt;/string&gt;
&lt;key&gt;NSSpeechRecognitionUsageDescription&lt;/key&gt;
&lt;string&gt;This application needs the speech recognition permission&lt;/string&gt;
</pre>
<p>(注意:上述权限将在开始语音识别之前向用户显示一条消息)</p>
<h3 id="adding-required-variables">步骤 3:添加必需的变量</h3>
<p>在这一步中，您将添加维护应用程序状态所需的变量。例如，您必须需要一个变量来知道语音识别是否启动。这将有助于根据各种情况显示和隐藏小部件。</p>
<p>以下是您需要的一些重要变量:</p>
<pre class="language-dart hljs">// 1.
late SpeechRecognition _speech;
// 2.
bool _isSpeechStarted = false;
// 3.
bool _isListening = false;
// 4.
String transcription = '';
String currentText = '';
// 5.
bool _isEndOfSpeech = false;
</pre>
<ol>
<li>这将用于创建<code>SpeechRecognition</code>的实例，并在以后访问它来开始和停止监听</li>
<li>这将用于显示/隐藏麦克风和停止按钮</li>
<li>这将用于显示/隐藏“收听…”文本。虽然我们可以使用之前的变量(即<code>_isSpeechStarted</code>)，但是这个变量有助于了解用户是否在实际说话</li>
<li>这是为了知道语音识别已经停止</li>
</ol>
<h3 id="building-the-page-ui">步骤 4:构建页面 UI</h3>
<p>页面 UI 由两个主要部分组成。第一部分显示语音助手和用户之间的对话；第二部分显示开始和停止语音识别的区域。</p>
<p>下面是这种情况下最少的代码:</p>
<pre class="language-dart hljs">SafeArea(
  child: Scaffold(
    backgroundColor: Colors.white,
    bottomNavigationBar: Container(
      height: 200,
      color: Colors.white,
      child: Column(
        mainAxisAlignment: MainAxisAlignment.spaceEvenly,
        children: [
          // 1. &lt;-- SEE HERE
          if (!_isSpeechStarted) ...[
            FloatingActionButton(
              backgroundColor: const Color(0xff764abc),
              child: Icon(
                Icons.mic,
                size: 35,
              ),
              onPressed: () {
                _startSpeechRecognition();
              },
            ),
          ] else ...[
            FloatingActionButton(
              backgroundColor: const Color(0xff764abc),
              child: Icon(
                Icons.stop,
                size: 35,
              ),
              onPressed: () {
                _stopSpeechRecognition();
              },
            ),
          ],
          // 2. &lt;-- SEE HERE
          if (_isListening) ...[
            Text(
              kListening,
              style: GoogleFonts.nunito(
                  textStyle:
                      TextStyle(color: Colors.black, fontSize: 22.5)),
            ),
          ],
        ],
      ),
    ),
    appBar: AppBar(
      title: Text('Voice Assistant'),
      backgroundColor: const Color(0xff764abc),
    ),
    body: Container(
      padding: EdgeInsets.all(16),
      child: SingleChildScrollView(
        child: Column(
          children: [
            SizedBox(
              height: 10,
            ),
            Row(
              mainAxisAlignment: MainAxisAlignment.end,
              children: [
                Text(
                  _ttsGreet,
                  style: GoogleFonts.poppins(
                    textStyle: TextStyle(
                        fontSize: 30.5, fontWeight: FontWeight.bold),
                  ),
                ),
              ],
            ),
            // 3. &lt;-- SEE HERE
            TextField(
              controller: _myController,
              readOnly: true,
              onChanged: (String text) {
                setState(() {
                  _isContentsPresent = text.isNotEmpty;
                });
              },
              //focusNode: _nodeText1,
              cursorColor: Colors.grey,
              style:
                  GoogleFonts.poppins(textStyle: TextStyle(fontSize: 30.5)),
              keyboardType: TextInputType.multiline,
              maxLines: null,
              decoration: InputDecoration(
                border: InputBorder.none,
                hintStyle: GoogleFonts.nunito(),
              ),
            ),
          ],
        ),
      ),
    ),
  ),
);
</pre>
<p>下面是上面代码的简要概述:</p>
<ol>
<li>该部分包含两个<a href="https://api.flutter.dev/flutter/material/FloatingActionButton-class.html" target="_blank" rel="noopener">浮动动作按钮</a>；一个启动语音识别，另一个停止。但是，基于<code>_isSpeechStarted</code>变量只显示一个</li>
<li>这用于显示/隐藏“Listening…”文本</li>
<li>语音到文本的结果(实际的用户语音命令)显示在这里。这里使用了<code>TextField</code>小部件，而不是<code>Text</code>小部件，使用户能够编辑语音命令(如果需要的话)</li>
</ol>
<p>下面是如何将代码翻译到设计中:</p>
<p><img data-attachment-id="122832" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/code-translated-design-2/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png" data-orig-size="730,608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="code-translated-design" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design-300x250.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png" decoding="async" class="aligncenter wp-image-122832 size-full jetpack-lazy-image" src="../Images/fe6b97fd2e34f2da7b288ce321eaf294.png" alt="Code Translated Design" data-lazy-srcset="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png 730w, https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design-300x250.png 300w" data-lazy-sizes="(max-width: 730px) 100vw, 730px" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png"/></p><noscript><img data-lazy-fallback="1" data-attachment-id="122832" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/code-translated-design-2/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png" data-orig-size="730,608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="code-translated-design" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design-300x250.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png" decoding="async" loading="lazy" class="aligncenter wp-image-122832 size-full" src="../Images/fe6b97fd2e34f2da7b288ce321eaf294.png" alt="Code Translated Design" srcset="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png 730w, https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design-300x250.png 300w" sizes="(max-width: 730px) 100vw, 730px" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/code-translated-design.png"/></noscript>
<h3 id="adding-speech-recognitioni">步骤 5:添加语音识别方法</h3>
<p>设置完变量和页面 UI 后，就该调用负责驱动语音识别特性的插件方法了。</p>
<p>下面是您将用来启动和停止识别服务的一些重要方法。</p>
<pre class="language-dart hljs">// 1.
void _activateSpeechRecognizer() {
  _requestPermission();
  _speech = new SpeechRecognition();
  _speech.setAvailabilityHandler(onSpeechAvailability);
  _speech.setRecognitionStartedHandler(onRecognitionStarted);
  _speech.setRecognitionResultHandler(onRecognitionResult);
  _speech.setRecognitionCompleteHandler(onRecognitionComplete);
  _speech
      .activate()
      .then((res) =&gt; setState(() =&gt; _speechRecognitionAvailable = res));
}
// 2.
void onRecognitionResult(String text) {
  if (_isEndOfSpeech) {
    _isEndOfSpeech = false;
    return;
  }
  setState(() {
    transcription = text;
    _isListening = true;
    print('recognized text is- $transcription');
    _myController.text = transcription;
    _myController.selection = TextSelection.fromPosition(
        TextPosition(offset: _myController.text.length));
  });
}
// 3.
void onRecognitionComplete() {
  print('Recognition Completed');

  if (transcription.isNotEmpty) {
    _isContentsPresent = true;
    _processRequest(transcription);
    _toggleSpeechRecognitionStatus(isSpeechStarted: false);
  }
}
</pre>
<ol>
<li>这将在后台激活语音识别器。页面一加载，就必须调用这个函数</li>
<li>这将在<code>TextField</code>小工具上输出识别结果</li>
<li>当用户完成提供语音命令时，将调用这个函数。在这里，您可以获取转录(语音转换为文本)并执行业务逻辑或任何您想对转录执行的操作</li>
</ol>
<p>厉害！您现在知道如何添加语音到文本支持。让我们假设您已经处理了请求，是时候说出结果了。让我们看看如何做到这一点。</p>
<h2 id="adding-text-to-speech">在 Flutter 应用程序中添加文本到语音</h2>
<p>在示例应用中，在屏幕上显示用户的语音命令后，语音命令被处理，结果由语音助手读出(除了在屏幕上显示之外)。</p>
<p>您可以通过利用<a href="https://pub.dev/packages/text_to_speech" target="_blank" rel="noopener">文本到语音</a> (TTS)插件来实现这样的需求。它可以在 iOS、Android、web 和 macOS 上运行。有了这个插件，你还可以改变声音的<strong>音量</strong>、<strong>速率、</strong>和<strong>音高</strong>。</p>
<p>以下是添加文本到语音转换支持的分步说明:</p>
<h3 id="step-1-adding-dependencies">步骤 1:添加依赖关系</h3>
<p>在<code>pubspec.yaml</code>文件中添加<a href="https://pub.dev/packages/text_to_speech" target="_blank" rel="noopener">文本到语音</a>的依赖关系。</p>
<p><code>pubspec.yaml</code>文件中的内容应该是这样的:</p>
<pre class="language-dart hljs">dependencies:
  flutter:
    sdk: flutter
  cupertino_icons: ^1.0.2
  speech_recognition: ^0.3.0+1 
  text_to_speech:  #NEW
</pre>
<h3 id="step-2-adding-permissions">步骤 2:添加权限</h3>
<p>对于朗读文本的插件，您只需启用 Android 平台的权限。</p>
<p>下面是<code>AndroidManifest.xml</code>(位于 your _ project/Android/app/src/main/Android manifest . XML)文件的样子:</p>
<pre class="language-dart hljs">&lt;manifest xmlns:android="http://schemas.android.com/apk/res/android"
    package="com.example.speech_to_text_demo"&gt;

    &lt;queries&gt;
        &lt;package android:name="com.google.android.googlequicksearchbox"/&gt;
        &lt;intent&gt;
            &lt;action android:name="android.intent.action.TTS_SERVICE" /&gt;
        &lt;/intent&gt;
    &lt;/queries&gt;

   &lt;application
    &lt;/application&gt;
&lt;/manifest&gt;
</pre>
<h3 id="step-3-adding-required-variables">步骤 3:添加必需的变量</h3>
<p>在这一步中，您将添加启动并将消息传递给 TTS(文本到语音)服务所需的变量。</p>
<p>以下是您需要的一些变量:</p>
<pre class="language-dart hljs">// 1.
TextToSpeech tts = TextToSpeech();
// 2.
String _ttsGreet = 'How may I help you?';
// 3.
String _ttsStaticResult = 'Its very hot today';
</pre>
<ol>
<li>这将创建一个<code>TextToSpeech</code>实例，您可以用它来触发 TTS 服务</li>
<li>这是页面加载后显示的问候消息</li>
<li>这是为了显示和说出一个假消息</li>
</ol>
<h3 id="step-4-building-the-page-ui">步骤 4:构建页面 UI</h3>
<p>页面 UI 只是在一个文本小部件中显示一条问候消息和一条回答用户查询的消息(在用户查询下方)。</p>
<p>为了简单起见，页面 UI 保持简单。您可以扩展它并使用 ListView 来构建最符合您需求的灵活的 UI。</p>
<p>代码如下所示:</p>
<pre class="language-dart hljs">if (_isShowResult)
  Row(
    mainAxisAlignment: MainAxisAlignment.end,
    children: [
      Text(
        _ttsStaticResult,
        //textAlign: TextAlign.end,
        style: GoogleFonts.poppins(
          textStyle: TextStyle(
              fontSize: 30.5, fontWeight: FontWeight.bold),
        ),
      ),
    ],
  ),
</pre>
<p><img data-attachment-id="122834" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/page-ui-example/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png" data-orig-size="730,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="page-ui-example" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example-300x186.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png" decoding="async" class="aligncenter wp-image-122834 size-full jetpack-lazy-image" src="../Images/253265e33e8047910372e476c0ff41f7.png" alt="Page UI Example" data-lazy-srcset="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png 730w, https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example-300x186.png 300w" data-lazy-sizes="(max-width: 730px) 100vw, 730px" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png"/></p><noscript><img data-lazy-fallback="1" data-attachment-id="122834" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/page-ui-example/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png" data-orig-size="730,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="page-ui-example" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example-300x186.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png" decoding="async" loading="lazy" class="aligncenter wp-image-122834 size-full" src="../Images/253265e33e8047910372e476c0ff41f7.png" alt="Page UI Example" srcset="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png 730w, https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example-300x186.png 300w" sizes="(max-width: 730px) 100vw, 730px" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/page-ui-example.png"/></noscript>
<h3 id="step-5-adding-text">步骤 5:添加文本</h3>
<p>如果您已经设置了变量和页面 UI，那么您可以通过在<code>TextToSpeech</code>的实例上调用<code>speak()</code>方法，在处理用户查询之后触发语音。</p>
<p>你可以这样做:</p>
<pre class="language-dart hljs">_processRequest(String transcription) {
  // Process request here
  /// Your business logic here
  //Speak out the result
  setState(() {
    _isShowResult = true;
  });
  _tts(_ttsStaticResult);
}

_tts(String message) {
  tts.speak(message); //&lt;-- SEE HERE
}
</pre>
<p>恭喜你！现在您知道如何添加文本到语音的支持。</p>
<h2 id="enabling-continuous-listening-on-android">在 Android 上实现持续收听</h2>
<p>当你运行带有语音识别插件的应用程序时，你可能会发现 Android 中的语音识别与 iOS 略有不同。</p>
<p>在安卓系统中，当你启动服务，一会儿不说话，系统会自动停止监听(在 iOS 系统中不是这样的)。</p>
<p>从技术上来说，它应该保持服务开放，直到用户开始说话——插件目前没有解决方案，所以我会解释如何自己修复它。</p>
<p>在 Android 上启用持续监听的步骤如下:</p>
<ol>
<li>下载插件代码并将其放在 lib/custom_package 文件夹中</li>
<li>在 lib/custom package/package folder/Android/src/main/Java/BZ/rxla/flutter/speech recognition 打开<code>SpeechRecognitionPlugin</code>文件。</li>
<li>用以下代码替换 onError 方法</li>
</ol>
<pre class="language-dart hljs">@Override
public void onError(int error) {
Log.d(LOG_TAG, "onError : " + error);
// handling ok google error
if (performingSpeechSetup &amp;&amp; error == SpeechRecognizer.ERROR_NO_MATCH) return;

// Restart listening in case of user has not said anything yet and is still listening i.e not stopped by user
if (!isStopped &amp;&amp; error == SpeechRecognizer.ERROR_NO_MATCH) {
    error7count += 1;
if (error7count &amp;gt; 0) {
    Log.d(LOG_TAG, "handle error : " + error);
    speech.startListening(recognizerIntent);
    return;
}
}
speechChannel.invokeMethod("speech.onSpeechAvailability", false);
speechChannel.invokeMethod("speech.onError", error);
}
</pre>
<p>这里的想法是当遇到<code>SpeechRecognizer.ERROR_NO_MATCH</code>错误(当服务自动停止时弹出)时重新启动语音识别。</p>
<p>按照上面的代码进行更改后，只要用户手动停止，语音识别服务就会一直运行(这正是我们想要的)。</p>
<p>它看起来是这样的:</p>
<p><img data-attachment-id="122836" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/speech-recognition-service/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png" data-orig-size="730,449" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="speech-recognition-service" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service-300x185.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png" decoding="async" class="aligncenter wp-image-122836 size-full jetpack-lazy-image" src="../Images/97f710392fbfa8fbfc0cb45e10f88b73.png" alt="Speech Recognition Service" data-lazy-srcset="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png 730w, https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service-300x185.png 300w" data-lazy-sizes="(max-width: 730px) 100vw, 730px" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png"/></p><noscript><img data-lazy-fallback="1" data-attachment-id="122836" data-permalink="https://blog.logrocket.com/adding-speech-to-text-text-to-speech-support-flutter-app/attachment/speech-recognition-service/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png" data-orig-size="730,449" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="speech-recognition-service" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service-300x185.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png" decoding="async" loading="lazy" class="aligncenter wp-image-122836 size-full" src="../Images/97f710392fbfa8fbfc0cb45e10f88b73.png" alt="Speech Recognition Service" srcset="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png 730w, https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service-300x185.png 300w" sizes="(max-width: 730px) 100vw, 730px" data-original-src="https://blog.logrocket.com/wp-content/uploads/2022/07/speech-recognition-service.png"/></noscript>
<p>完整的源代码可以在<a href="https://github.com/pinkeshdarji/speech_to_text_and_text_to_speech" target="_blank" rel="noopener">这里</a>找到。</p>
<h2 id="conclusion">结论</h2>
<p>添加语音到文本和文本到语音功能可以为用户提供与您的应用程序交互的附加功能。</p>
<p>在本教程中，我们首先看了如何添加语音到文本，然后探讨了添加文本到语音服务。</p>
<p>我们通过一步一步的说明来设置变量、UI 和方法。我们还学习了如何为 Android 设备启用持续监听。</p><div class="code-block code-block-2">
<div class="blog-plug base-cta"><h2>使用<a class="signup" href="https://lp.logrocket.com/blg/signup" target="_blank" rel="noopener noreferrer"> LogRocket </a>消除传统错误报告的干扰</h2>
<a href="https://lp.logrocket.com/blg/signup" class="signup" target="_blank" rel="noopener noreferrer"><img class="alignnone size-full wp-image-46 jetpack-lazy-image" src="../Images/d6f5a5dd739296c1dd7aab3d5e77eeb9.png" alt="LogRocket Dashboard Free Trial Banner" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg.png"/><noscript><img data-lazy-fallback="1" class="alignnone size-full wp-image-46" src="../Images/d6f5a5dd739296c1dd7aab3d5e77eeb9.png" alt="LogRocket Dashboard Free Trial Banner" data-original-src="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg.png"/></noscript></a>
<p><a href="https://lp.logrocket.com/blg/signup" target="_blank" rel="noopener noreferrer"> LogRocket </a>是一个数字体验分析解决方案，它可以保护您免受数百个假阳性错误警报的影响，只针对几个真正重要的项目。LogRocket 会告诉您应用程序中实际影响用户的最具影响力的 bug 和 UX 问题。</p>
<p>然后，使用具有深层技术遥测的会话重放来确切地查看用户看到了什么以及是什么导致了问题，就像你在他们身后看一样。</p>
<p>LogRocket 自动聚合客户端错误、JS 异常、前端性能指标和用户交互。然后 LogRocket 使用机器学习来告诉你哪些问题正在影响大多数用户，并提供你需要修复它的上下文。</p>
<p>关注重要的 bug—<a class="signup" href="https://lp.logrocket.com/blg/signup-issue-free" target="_blank" rel="noopener noreferrer">今天就试试 LogRocket】。</a></p></div></div>

<p class="clearfix"/>
<p class="clearfix"/>
</article>

</div>    
</body>
</html>