<html>
<head>
<title>Kubernetes log aggregation - LogRocket Blog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Kubernetes日志聚合- LogRocket博客</h1>
<blockquote>原文：<a href="https://blog.logrocket.com/kubernetes-log-aggregation/#0001-01-01">https://blog.logrocket.com/kubernetes-log-aggregation/#0001-01-01</a></blockquote><div><article class="article-post">
<h3>在Kubernetes集群上进行可伸缩日志记录的最简单的起点</h3>
<p>所以你是一个<a href="https://kubernetes.io/" target="_blank" rel="noopener noreferrer"> Kubernetes </a>集群的骄傲的新主人，你有一些<a href="https://en.wikipedia.org/wiki/Microservices" target="_blank" rel="noopener noreferrer">微服务</a>部署在上面。现在，如果你知道他们都在做什么就好了。</p>
<p>在微服务领域，实现日志聚合势在必行。</p>
<p>事情可能会很快失去控制——随着我们的应用程序的增长，试图弄清楚发生了什么很容易变得不知所措。</p>
<p>你可能已经读过关于这个主题的其他博客文章。</p>
<p>它们通常是关于流体和弹性的研究。这似乎是默认的解决方案，但设置通常过于复杂和困难。</p>
<p>如果你想了解引擎盖下发生了什么呢？祝你好运。如果你更喜欢轻量级的解决方案呢？再试一次。</p>
<p>在这篇博文中，我们将探索如何构建自己的Kubernetes日志聚合器。</p>
<p>我们将看一个名为<strong> Loggy </strong>的Node.js微服务示例，它被设计为将来自Kubernetes的日志转发到外部日志收集器。</p>
<p>这不是企业级的，但我们没有理由不能在以后实现。</p>
<p>目前，我们将专注于构建适合小型应用程序(可能是MVP)的东西，同时我们将学习Kubernetes日志架构和<a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener noreferrer"> DaemonSets </a>。</p>
<h3>日志架构</h3>
<p>Kubernetes中的日志记录是如何工作的？</p>
<p>图1给出了一个图形描述。</p>
<p>我们有一个包含多个<a href="https://kubernetes.io/docs/concepts/architecture/nodes/" target="_blank" rel="noopener noreferrer">节点</a>的Kubernetes集群。每个节点运行多个<a href="https://en.wikipedia.org/wiki/OS-level_virtualization" target="_blank" rel="noopener noreferrer">容器</a>(它们各自包含在一个<a href="https://kubernetes.io/docs/concepts/workloads/pods/" target="_blank" rel="noopener noreferrer">容器内)</a>。</p>
<p>我们的微服务应用程序由整个集群中的所有容器组成。每个容器产生自己的输出，这些输出由Kubernetes自动收集并存储在节点上。</p>
<p>我们需要一个日志聚合系统来合并这些日志文件，并将输出转发给外部日志收集器。</p>
<figure id="attachment_10732" aria-describedby="caption-attachment-10732" class="wp-caption aligncenter"><img data-attachment-id="10732" data-permalink="https://blog.logrocket.com/kubernetes-log-aggregation/kubernetes-cluster-figure-1-nocdn/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png" data-orig-size="958,279" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Kubernetes-cluster-figure-1-nocdn" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn-300x87.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png" decoding="async" class="wp-image-10732 jetpack-lazy-image" src="../Images/8f112d962123baf380e7d934017ea615.png" alt="A conceptual illustration of a Kubernetes cluster" data-lazy-srcset="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png 958w, https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn-300x87.png 300w, https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn-768x224.png 768w" data-lazy-sizes="(max-width: 730px) 100vw, 730px" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png"/><noscript><img data-lazy-fallback="1" data-attachment-id="10732" data-permalink="https://blog.logrocket.com/kubernetes-log-aggregation/kubernetes-cluster-figure-1-nocdn/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png" data-orig-size="958,279" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Kubernetes-cluster-figure-1-nocdn" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn-300x87.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png" decoding="async" loading="lazy" class="wp-image-10732" src="../Images/8f112d962123baf380e7d934017ea615.png" alt="A conceptual illustration of a Kubernetes cluster" srcset="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png 958w, https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn-300x87.png 300w, https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn-768x224.png 768w" sizes="(max-width: 730px) 100vw, 730px" data-original-src="https://blog.logrocket.com/wp-content/uploads/2019/12/Kubernetes-cluster-figure-1-nocdn.png"/></noscript><figcaption id="caption-attachment-10732" class="wp-caption-text">Figure 1: A conceptual log aggregation system on Kubernetes</figcaption></figure>
<p>我们可以使用一个<strong> DaemonSet </strong>在Kubernetes上实现这样一个系统。这就是我们将如何在每个节点上运行我们的<strong> Loggy </strong>微服务，并从那里让它访问节点的累积日志文件。</p>
<p>图2显示了如何将每个容器的输出收集到单独的日志文件中，然后由Loggy拾取:</p>
<figure id="attachment_10737" aria-describedby="caption-attachment-10737" class="wp-caption aligncenter"><img data-attachment-id="10737" data-permalink="https://blog.logrocket.com/kubernetes-log-aggregation/node-container-figure-2-nocdn/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png" data-orig-size="615,463" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Node-container-figure-2-nocdn" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn-300x226.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png" decoding="async" class="wp-image-10737 jetpack-lazy-image" src="../Images/1fc24fd77e55948803ad1ee9273d1c2c.png" alt="" data-lazy-srcset="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png 615w, https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn-300x226.png 300w" data-lazy-sizes="(max-width: 730px) 100vw, 730px" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png"/><noscript><img data-lazy-fallback="1" data-attachment-id="10737" data-permalink="https://blog.logrocket.com/kubernetes-log-aggregation/node-container-figure-2-nocdn/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png" data-orig-size="615,463" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Node-container-figure-2-nocdn" data-image-description="" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn-300x226.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png" decoding="async" loading="lazy" class="wp-image-10737" src="../Images/1fc24fd77e55948803ad1ee9273d1c2c.png" alt="" srcset="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png 615w, https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn-300x226.png 300w" sizes="(max-width: 730px) 100vw, 730px" data-original-src="https://blog.logrocket.com/wp-content/uploads/2019/12/Node-container-figure-2-nocdn.png"/></noscript><figcaption id="caption-attachment-10737" class="wp-caption-text">Figure 2: Our log aggregator microservice (Loggy) can access the logs from every container running on the node</figcaption></figure>
<h3>获取示例代码</h3>
<p>这篇博文的示例代码可以在GitHub的https://GitHub . com/Ashley Davis/kubernetes-log-aggregation-example上找到。</p>
<p>示例代码旨在让您复制这篇博文中的结果。</p>
<p>要跟进，您需要:</p>
<ul>
<li>在上进行实验的一个<a href="http://www.the-data-wrangler.com/kub-cluster-quick/" target="_blank" rel="noopener noreferrer"> Kubernetes集群(最好不是你公司的生产集群)。</a></li>
<li>运行命令的Linux风格的终端。</li>
<li>我用的是Ubuntu Linux，</li>
<li>MacOS应该也能工作</li>
<li>Windows上的Git Bash</li>
<li>Docker安装了，这样您就可以构建和推送映像了。</li>
<li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener noreferrer"> Kubectl安装了</a>并通过了身份验证，这样您就可以与您的集群进行交互了。</li>
</ul>
<h3>基本日志记录</h3>
<p>如果您还没有尝试过使用Kubernetes进行日志记录的更基本的方法，那么您应该在深入研究更高级的日志聚合之前先尝试一下。</p>
<p>如果您已经设置使用<a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/" target="_blank" rel="noopener noreferrer"> Kubernetes仪表板，</a>这可能是从任何pod查看最近日志的最简单方式。</p>
<p>否则，使用<code>kubectl logs</code>命令从任何pod中提取记录:</p>
<pre>kubectl logs &lt;pod-name&gt;</pre>
<p>这些基本方法是一个很好的起点。在Kubernetes上构建应用程序的早期，您可以从中获益匪浅。</p>
<p>不过，迟早，您会希望将日志集中到一个易于查看和搜索的地方。</p><div class="code-block code-block-54">
<hr/>
<h3>更多来自LogRocket的精彩文章:</h3>

<hr/></div>
<h3>要记录的东西</h3>
<p>在我们试验日志聚合之前，我们需要有一个容器在运行并生成输出。</p>
<p>清单1是一个将计数器pod部署到Kubernetes的YAML文件。这就创建了一个生成连续输出流的容器。</p>
<p><strong>清单1:Kubernetes计数器pod生成输出的YAML</strong></p>
<pre>apiVersion: v1
    kind: Pod
    metadata:
      name: counter
    spec:
      containers:
      - name: count
        image: busybox
        args: [/bin/sh, -c,
                'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']</pre>
<p>使用以下命令将计数器pod部署到Kubernetes:</p>
<pre>kubectl apply -f ./scripts/kubernetes/counter.yaml</pre>
<p>给计数器盒一些时间来启动，然后检查它是否正在生成输出:<br/> <code>kubectl logs counter</code></p>
<p>您应该会看到计数器窗格输出的连续序列。</p>
<h3>探索Kubernetes日志文件</h3>
<p>现在让我们创建一个测试pod，我们将使用它来研究在一个节点上收集的日志文件。</p>
<p>清单2是一个YAML文件，它将我们的新pod部署为Kubernetes DaemonSet，这样pod就可以在集群中的每个节点上运行。我们将用它来访问日志文件。</p>
<p><strong>清单2:Kubernetes testDaemonSet在节点上浏览日志文件的YAML:</strong></p>
<pre>apiVersion: extensions/v1beta1
    kind: DaemonSet
    metadata:
      name: test
      namespace: kube-system
      labels:
        test: test
    spec:
      template:
        metadata:
          labels:
            test: test
        spec:
          serviceAccountName: test
          containers:
          - name: test
            image: ubuntu:18.04
            args: [/bin/sh, -c, 'sleep infinity']
            volumeMounts:
            - name: varlog
              mountPath: /var/log
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
          volumes:
          - name: varlog
            hostPath:
              path: /var/log
          - name: varlibdockercontainers
            hostPath:
              path: /var/lib/docker/containers</pre>
<p>在清单2中，我们只是启动了一个Ubuntu Linux容器，并使用命令<code>sleep infinity</code>让容器永远运行(什么也不做)。</p>
<p>注意目录<code>/var/log</code>和<code>/var/lib/docker/containers</code>是如何安装到测试盒中的。这使我们能够访问包含日志文件的目录。</p>
<p>使用以下命令将DaemonSet部署到群集:</p>
<p><code>kubectl apply -f ./scripts/kubernetes/test-run.yaml<br/> </code> <br/>让它启动一会儿，我们将让测试舱在集群中的每个节点上运行。运行<code>get pods</code>命令列出pod:</p>
<pre>kubectl --namespace kube-system get pods</pre>
<p>我们只列出了来自<code>kube-system</code>名称空间的pod，这是我们部署新DaemonSet的地方。在列表中，您应该可以看到测试盒。</p>
<p>集群中的每个节点都应该运行一个pod。如果您有三个节点，您将看到三个这样的测试箱。</p>
<p>选择第一个测试容器，并在其中运行shell，如下所示:</p>
<pre>kubectl --namespace kube-system get pods</pre>
<p>只要确保将<code>test-4hft2</code>替换为您的pod的实际名称即可。这是为pod生成的名称，在您的群集中会有所不同。这将在您的容器中打开一个命令行shell，以便您可以向它发出命令。</p>
<p>让我们用它来研究日志文件。</p>
<p>将目录更改为包含日志文件的已装入卷:</p>
<pre>cd /var/log/containers</pre>
<p>现在查看目录的内容:</p>
<pre>ls</pre>
<p>您应该在这里看到一堆日志文件。找到计数器窗格的日志文件。</p>
<p>如果您没有看到它，这可能意味着您连接到错误的测试盒。</p>
<p>因为它是一个DaemonSet，所以您在群集中的每个节点上都运行了其中一个，而您可能连接到了一个运行在错误节点上的节点。</p>
<p>如果是这种情况，请尝试依次连接到其他测试箱，直到找到包含计数器箱日志文件的测试箱。</p>
<p>打印计数器窗格日志文件的内容，如下所示:</p>
<pre>cat counter_default_count-7a6a001c407ef818ea85f28685b829f51512d70b18a4bf01f.log</pre>
<p>您需要将日志文件的名称替换为您在容器中实际看到的名称，因为它为您的集群生成的唯一ID与我的集群不同。</p>
<p>计数器窗格日志文件的内容如下所示:</p>
<pre>{"log":"0: Sun Dec  1 03:33:17 UTC 2019\n","stream":"stdout","time":"2019-12-01T03:33:17.223963224Z"}
{"log":"1: Sun Dec  1 03:33:18 UTC 2019\n","stream":"stdout","time":"2019-12-01T03:33:18.224897474Z"}
{"log":"2: Sun Dec  1 03:33:19 UTC 2019\n","stream":"stdout","time":"2019-12-01T03:33:19.225738311Z"}
{"log":"3: Sun Dec  1 03:33:20 UTC 2019\n","stream":"stdout","time":"2019-12-01T03:33:20.226719734Z"}</pre>
<p>您可以立即看到日志文件的每一行都是一个JSON对象。扫描这个日志文件的结构给了我们一些应该如何解析它的线索。</p>
<p>当您浏览完测试窗格中的日志文件后，请删除DaemonSet，如下所示:</p>
<pre>kubectl delete -f ./scripts/kubernetes/test-run.yaml</pre>
<h3>处理日志聚合</h3>
<p>在我们真正处理日志聚合之前，我们必须回答一系列问题。</p>
<p>我们如何找到日志文件？</p>
<p>Globby 是一个很棒的npm包，用于基于<a href="https://en.wikipedia.org/wiki/Glob_(programming)" target="_blank" rel="noopener noreferrer"> globs </a>查找文件。</p>
<p>我们将使用以下glob来查找每个节点上的所有日志文件:</p>
<pre>/var/log/containers/*.log</pre>
<p>我们将如何消除系统日志文件？</p>
<p>任何给定节点上的日志文件目录不仅包含我们的应用程序的日志，还包含构成Kubernetes系统的所有pods的日志。</p>
<p>我们通常只关心应用程序的输出，所以我们需要一种方法来排除系统日志文件(包括Loggy微服务本身)。</p>
<p>幸运的是，我们也可以使用Globby通过使用glob排除系统日志文件来做到这一点:</p>
<pre>!/var/log/containers/*kube-system*.log</pre>
<p>感叹号表示我们希望排除符合该模式的日志文件。</p>
<p>将我们的两个globs放在一起，我们就有了一个标识感兴趣的日志文件的规范:</p>
<pre>/var/log/containers/*.log
!/var/log/containers/*kube-system*.log</pre>
<p>我们如何跟踪日志文件？</p>
<p>当日志文件更新时，我们希望得到新输出的通知。为此，我们将使用<a href="https://github.com/lucagrulla/node-tail" target="_blank" rel="noopener noreferrer"> node-tail </a> npm包。</p>
<p>这种事情实际上有很多选择，但我选择了GitHub上星星最多的那个。</p>
<p>当新的日志文件创建时，我们将如何得到通知？</p>
<p>当新的pod部署到集群时，会创建新的日志文件。</p>
<p>我们需要监视文件系统，以了解何时可以跟踪新的日志文件。</p>
<p>为此，我们将使用npm模块<a href="https://github.com/paulmillr/chokidar" target="_blank" rel="noopener noreferrer"> chokidar </a>。</p>
<p>同样，这种事情还有其他选择，但是我以前用过chokidar，很高兴再次使用它。</p>
<p>我们将如何解析日志文件？</p>
<p>这部分很简单。我们已经确定日志文件中的每一行都是一个JSON对象。</p>
<p>我们将使用node-tail库来接收新行。我们将使用内置的JavaScript函数<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse" target="_blank" rel="noopener noreferrer"> JSON.parse </a>解析每个输入的输出行。</p>
<p>我们将把每个日志条目发送到哪里？</p>
<p>这部分完全取决于你，取决于你想在哪里存储你的日志。</p>
<p>您可以将日志存储在集群的数据库中，但这不是一个好主意——如果您的集群出现问题，您可能无法检索日志来诊断问题。</p>
<p>最好将日志转发到外部日志收集器。</p>
<p>一个很好的方法是通过HTTP POST请求发送批量日志。</p>
<p>在这篇博文中，我们将只在日志到达Loggy时打印日志。</p>
<h3>Loggy:可能是世界上最简单的Kubernetes日志聚合器</h3>
<p>这将我们带到Loggy，这可能是Kubernetes最简单和最小的日志聚合微服务。</p>
<p>清单3展示了Loggy的完整代码。</p>
<p>通读并注意以下内容:<br/>–<code>globby</code>标识日志文件；<br/>–<code>tail</code>跟踪新输出的每个日志文件；和<br/>–<code>chokidar</code>观察新的日志文件。</p>
<p><strong>清单Kubernetes上用于日志聚合的最简单的Node.js微服务</strong></p>
<pre>const tail = require("tail");
    const globby = require("globby");
    const chokidar = require("chokidar");
    
    //
    // The directory on the node containing log files.
    //
    const LOG_FILES_DIRECTORY = "/var/log/containers";
    
    //
    // A glob that identifies the log files we'd like to track.
    //
    const LOG_FILES_GLOB = [
         // Track all log files in the log files diretory.
        `${LOG_FILES_DIRECTORY}/*.log`,                 
    
         // Except... don't track logs for Kubernetes system pods.
        `!${LOG_FILES_DIRECTORY}/*kube-system*.log`,    
    ];
    
    //
    // Map of log files currently being tracked.
    //
    const trackedFiles = {};
    
    //
    // This function is called when a line of output is received 
    // from any container on the node.
    //
    function onLogLine(containerName, line) {
        //
        // At this point you should forward your logs to an external log collector.
        // For this simple example we'll just print them directly to the console.
        //
    
        // The line is a JSON object so parse it first to extract relevant data.
        const data = JSON.parse(line);     
        const isError = data.stream === "stderr"; // Is the output an error?
        const level = isError ? "error" : "info";
        console.log(`${containerName}/[${level}] : ${data.log}`);
    }
    
    //
    // Commence tracking a particular log file.
    //
    function trackFile(logFilePath) {
        const tail = new tail.Tail(logFilePath);
    
        // Take note that we are now tracking this file.
        trackedFiles[logFilePath] = tail; 
        
        // Super simple way to extract the container name from the log filename.
        const containerName = logFileName.split("-")[0]; 
    
        // Handle new lines of output in the log file.
        tail.on("line", line =&gt; onLogLine(containerName, line));
    
        // Handle any errors that might occur.
        tail.on("error", error =&gt; console.error(`ERROR: ${error}`));
    }
    
    //
    // Identify log files to be tracked and start tracking them.
    //
    async function trackFiles() {
        const logFilePaths = await globby(LOG_FILES_GLOB);
        for (const logFilePath of logFilePaths) {
            if (trackedFiles[logFilePaths]) {
                continue; // Already tracking this file, ignore it now.
            }
            
            // Start tracking this log file we just identified.
            trackFile(logFilePath); 
        }
    }
    
    async function main() {
        // Start tracking initial log files.
        await trackFiles();
    
        // Track new log files as they are created.
        chokidar.watch(LOG_FILES_GLOB) 
            .on("add", newLogFilePath =&gt; trackFile(newLogFilePath)); 
    }
    
    main() 
        .then(() =&gt; console.log("Online"))
        .catch(err =&gt; {
            console.error("Failed to start!");
            console.error(err &amp;&amp; err.stack || err);
        });</pre>
<p>对于清单3，您唯一要做的事情就是决定如何处理您的日志。</p>
<p>例如，您可以使用HTTP POST请求将批量日志发送到外部日志收集器。</p>
<p>清单4显示了将Loggy作为DaemonSet部署到Kubernetes的YAML文件。</p>
<p><strong>清单4:将Loggy部署到Kubernetes的YAML文件</strong></p>
<pre>apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: loggy
  namespace: kube-system
  labels:
    test: loggy
spec:
  template:
    metadata:
      labels:
        test: loggy
    spec:
      serviceAccountName: loggy
      containers:
      - name: loggy
        image: &lt;yourcontainerregistry&gt;/loggy:1
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers</pre>
<p>清单4中最重要的内容是卷如何从节点映射到容器。</p>
<p>节点上的目录<code>/var/log</code>和<code>/var/lib/docker/containers</code>包含从节点上所有pod收集的日志。</p>
<p>这些目录被挂载到Loggy的容器中，以便Loggy可以访问日志文件。</p>
<p>在部署清单4中的DaemonSet之前，您需要将<code>&lt;yourcontainerregistry&gt;</code>设置为您自己的容器注册中心的URL。</p>
<p>您必须将清单3构建到Docker映像theDockerfile <a href="https://github.com/ashleydavis/kubernetes-log-aggregation-example/blob/master/loggy/Dockerfile" target="_blank" rel="noopener noreferrer">中，因为它在示例代码库</a>中提供，并将它推送到同一个容器注册表中。现在，您可以使用以下命令将Loggy部署到Kubernetes集群:</p>
<pre>kubectl apply -f ./scripts/kubernetes/loggy.yaml</pre>
<p>Loggy正在从您的所有微服务中收集日志。要查看创建的窗格，请运行以下命令:</p>
<pre>kubectl --namespace=kube-system get pods</pre>
<p>您可以从system pods列表中挑选出Loggy的每个实例(集群中的每个节点都有一个实例)。然后可以使用<em> logs </em>命令查看每个节点的聚合日志(因为Loggy只是输出到控制台)。例如:</p>
<pre>kubectl --namespace=kube-system logs loggy-7h47q</pre>
<p>只需将<code>loggy-7h47q</code>更改为从<em> get pods </em>的输出中选择的一个实例名。</p>
<p>现在您只需要更新Loggy，让它将您的日志发送到集群之外的某个地方！</p>
<h3>结论</h3>
<p>在这篇博文中，我们探索了Kubernetes上日志聚合的绝对基础。</p>
<p>为了自己完成这个系统，您现在必须扩充清单3，并将您的日志存储在一个易于查看和搜索的地方。</p>
<p>我们将Loggy作为DaemonSet部署到Kubernetes集群。那就是让它在我们集群中的每个节点上运行。我们将节点的文件系统挂载到Loggy的容器中，这使得Loggy可以访问该节点上的日志文件。</p>
<h3>资源</h3>
<p>你可以在这里查看一个Kubernetes集群来进行实验。</p>
<p>你可以从我的新书<strong>Bootstrapping micro services</strong>中了解更多关于在Kubernetes上构建微服务应用的信息:</p>
<blockquote class="embedly-card" data-card-controls="1" data-card-align="center" data-card-theme="light">

<p>我读过的关于理解和实现微服务所需工具的最佳介绍。Chris Viner，Forged Development学习微服务开发的最好方法是构建一些东西！使用Docker、Kubernetes和Terraform引导微服务从零到完整的微服务项目，包括快速原型制作、开发和部署。</p>
</blockquote>
<p/>
<p>这篇博文的示例代码可从以下网址获得:</p>
<blockquote class="embedly-card" data-card-controls="1" data-card-align="center" data-card-theme="light">

<p>该报告包含相关博客文章的示例代码。单击此处支持我的工作这个示例演示了Kubernetes最简单的日志聚合，它使用一个微服务(Loggy)和一个DaemonSet，以便将微服务部署到集群上的每个节点。</p>
</blockquote>
<p/>
<p>以下是Kubernetes日志记录架构的文档:</p>
<blockquote class="embedly-card" data-card-controls="1" data-card-align="center" data-card-theme="light">

<p>应用程序日志可以帮助您了解应用程序内部发生了什么。这些日志对于调试问题和监控集群活动特别有用。大多数现代应用程序都有某种日志机制。同样，容器引擎被设计为支持日志记录。</p>
</blockquote>
<p>Kubectl cheat sheet:</p>
<p>这个页面包含一个常用kubectl命令和标志的列表。Kubectl自动完成BASH源代码&gt; ~/。bashrc #将自动完成永久添加到bash shell中。您还可以使用一个也支持完成的kubectl的简写别名:alias k = ku bectl complete-o default-F _ _ start _ ku bectl k ZSH源代码&gt; ~/。</p>
<blockquote class="embedly-card" data-card-controls="1" data-card-align="center" data-card-theme="light">

<p>This page contains a list of commonly used kubectl commands and flags. Kubectl autocomplete BASH source &gt; ~/.bashrc # add autocomplete permanently to your bash shell. You can also use a shorthand alias for kubectl that also works with completion: alias k=kubectl complete -o default -F __start_kubectl k ZSH source &gt; ~/.</p>
</blockquote>
<p>不要只记录Kubernetes–添加客户端日志聚合</p>
<div class="inline-plug cro19">
<h2>追踪生产JavaScript异常或错误的原因是耗时且令人沮丧的。如果您对监控前端错误、记录跨用户的网络请求以及将日志绑定到实际用户感兴趣，请尝试LogRocket 。<a class="signup" href="https://logrocket.com/signup/" target="_blank" rel="noopener noreferrer"><img data-attachment-id="46" data-permalink="https://blog.logrocket.com/vuex-showdown-mutations-vs-actions/1d0cd-1s_rmyo6nbrasp-xtvbaxfg/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg-e1565635879164.png" data-orig-size="730,412" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LogRocket dashboard free trial banner" data-image-description="&lt;p&gt;LogRocket is working on the perfect frontend bug report. Try it free today.&lt;/p&gt;&#10;" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg-e1565635879164.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg-e1565635879164.png" decoding="async" class="alignnone size-full wp-image-46 jetpack-lazy-image" src="../Images/e8a0ab42befa3b3b1ae08c1439527dc6.png" alt="LogRocket Dashboard Free Trial Banner" data-lazy-src="https://blog.logrocket.com/wp-content/uploads/2019/10/errors-screenshot.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-original-src="https://blog.logrocket.com/wp-content/uploads/2019/10/errors-screenshot.png"/><noscript><img data-lazy-fallback="1" data-attachment-id="46" data-permalink="https://blog.logrocket.com/vuex-showdown-mutations-vs-actions/1d0cd-1s_rmyo6nbrasp-xtvbaxfg/" data-orig-file="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg-e1565635879164.png" data-orig-size="730,412" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LogRocket dashboard free trial banner" data-image-description="&lt;p&gt;LogRocket is working on the perfect frontend bug report. Try it free today.&lt;/p&gt;&#10;" data-image-caption="" data-medium-file="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg-e1565635879164.png" data-large-file="https://blog.logrocket.com/wp-content/uploads/2017/03/1d0cd-1s_rmyo6nbrasp-xtvbaxfg-e1565635879164.png" decoding="async" class="alignnone size-full wp-image-46" src="../Images/e8a0ab42befa3b3b1ae08c1439527dc6.png" alt="LogRocket Dashboard Free Trial Banner" data-original-src="https://blog.logrocket.com/wp-content/uploads/2019/10/errors-screenshot.png"/></noscript></a><a href="https://logrocket.com/signup/" target="_blank" rel="noopener noreferrer">https://logrocket.com/signup/</a></h2>
<p>LogRocket 就像是网络应用的DVR，记录下你网站上发生的每一件事。LogRocket使您能够聚合和报告错误，以查看它们发生的频率以及它们影响了多少用户群。您可以轻松地重放发生错误的特定用户会话，以查看导致错误的用户操作。</p>
<p>LogRocket让你的应用程序记录带有标题+正文的请求/响应，以及关于用户的上下文信息，以全面了解问题。它还记录页面上的HTML和CSS，甚至可以重建最复杂的单页面应用程序的像素级完美视频。</p>
<p>增强您的JavaScript错误监控能力–––<a class="signup" href="https://logrocket.com/signup/" target="_blank" rel="noopener noreferrer">开始免费监控</a>。</p>
<p>Enhance your JavaScript error monitoring capabilities – – <a class="signup" href="https://logrocket.com/signup/" target="_blank" rel="noopener noreferrer">Start monitoring for free</a>.</p>
</div>

<p class="clearfix"/>
<p class="clearfix"/>
</article>

</div>    
</body>
</html>